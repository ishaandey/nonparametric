# (PART) Two Sample Scale {-}

# Summary {-}

> Goal: We've got two samples, and want to see if there's the significance difference in scale, or variance.

```{r}
x <- seq(-7, 7, length=100)
pdf.1 <- dnorm(x,0,1)
pdf.2 <- dnorm(x,0,2)

cdf.1 <- pnorm(x,0,1)
cdf.2 <- pnorm(x,0,2)

df <- data.frame(x, pdf.1, pdf.2, cdf.1, cdf.2)

ggplot(data=df, aes(x=x)) + 
  geom_line(aes(y = pdf.1), color = "red") + 
  geom_line(aes(y = pdf.2), color = "blue") 
```

## Background {-}

# F-Test
- $H_0: \sigma_1 = \sigma_2$
- $F = \frac{s^2_1}{s^2_2}$ 
- Assumes both pop dist are normally dist
- If normality is violated, then type I error probability will be greater than stated $\alpha$

# Siegel-Tukey

## Usage

- Use when two populations share a common location parameter

### Assumptions {-}

1. Two random (independent) samples
2. Both population distributions are continuous
3. Both populations **share same location parameter**

This is a 

## How it Works

We'll first pool and sort observations from smallest to largest. However, instead of ranking them as we did, we'll snake around, assigning lower ranks to the most extreme observations, and wind inwards.

More visually:

```{r}
sample1 <- c(10,15,20)
sample2 <- c(13,17)

df <- tibble(sample1, sample2=c(sample2, NA)) %>% t()
colnames(df) <- paste('Obs', 1:3)
kable(df) 
```

```{r}
pooled <- c(sample1, sample2) %>% sort()
ranks <- c(1,4,5,3,2)
df2 <- tibble(pooled, ranks) %>% t()
colnames(df2) <- paste0('Sample',c(1,2,2,2,1))
kable(df2) 
```

At this point, we can apply the *Wilcoxon Rank-Sum Test* to our resulting ranks:

```{r}
sample1 <- c(1,2)
sample2 <- c(4,5,3)

df <- tibble(sample1=c(sample1, NA), sample2) %>% t()
colnames(df) <- paste('Obs', 1:3)
kable(df) 
```


### Background
- $X_i = \mu + \sigma_1 \epsilon_{ix}$
- $Y_j= \mu + \sigma_2 \epsilon_{jy}$
- Where $\epsilon$ are iid RV w/ median = 0
- Two random (independent) samples
- Assuming *common location parameter*

Population w/ *greater variability* will have more *extreme* observations have *smaller* ranks, so we should conduct a *lower-tail* wilcoxon test.

### Hypothesis Test

- **Null Hypothesis**: $H_0: \sigma_1 = \sigma_2$
- **Lower Tail**: $H_a: \sigma_1 > \sigma_2$

## Code
```{r}
x <- c(-1,0,3,6,7)
y <- c(1,2,3,4,5)

library('DescTools')
SiegelTukeyTest(x,y,alternative='greater')
```

## Ansari-Bradley

- Average the ranks going both ways (starting w/ largest, and starting w/ smallest).
- Have to solve for p-value through test of permutations, since its using average ranks

```{r}
ansari.test(x, y, alternatve='greater')
```


# Test on Deviances

## Usage
- Sometimes you can't make the assumption that the location parameters are the same

### Assumptions
1. Random, independent samples
2. Both pop dist are cts



## Procedure
### Test Statistic

Model:

- $X_i = \mu_1 + \sigma_1 \epsilon_{ix}$
- $Y_j= \mu_1 + \sigma_2 \epsilon_{jy}$
- $\epsilon$ is iid w/ median = 0

Deviances: 

- $dev_{ix} = X_i - \mu_1$   
- $dev_{jy} = Y_j - \mu_2$  
- Deviances are centered at 0, so only difference is attributable to different scale parameters

**Ratio of absolute Mean Differences** (RMD):

- $RMD = \frac{\sum |dev_{ix}|/m}{\sum |dev_{jy}|/n}$
- Large values of RMD indicate that pop 1 (numerator) has greater variability. - Small values of RMD indicate that pop 2 (denom) has greater variability.

### Hypothesis Test
1. Compute estimated deviance *for each observation*
- $\hat{dev_{ix}} = X_i - median_1$
- $\hat{dev_{jy}}  = Y_j - median_2$
2. Solve for estimated RMD: $\hat{RMD} = \frac{\sum |\hat{dev_{ix}}|/m}{\sum |\hat{dev_{jy}}|/n}$
3. Pool $m$ obs from sample 1 and $n$ obs from sample 2, then permute obs s.t. $m$ are assigned to 1, and $n$ are assigned to 2. Compute estimated RMD for this permutation
4. Do this for each of $\binom {m+n}{m} = \frac {(m+n)!}{m!n!}$ times
5. p-value is fraction of permutations as or more extreme that observed
<br>    $P_{lower\ tail}$ =  $\frac{\text{# of }\hat{RMD}s~\geq~ \hat{RMD}_{obs}}{\binom {m+n}{m}}$
<br>    $P_{upper\ tail}$ =  $\frac{\text{# of }\hat{RMD}s~\leq~ \hat{RMD}_{obs}}{\binom {m+n}{m}}$
<br>    $P_{two\ sided}$ =  $\frac{\text{# of }\hat{RMD}s~\text{more extreme than}~\hat{RMD}_{obs}\text{ or } \frac{1}{\hat{RMD}_{obs}} }{\binom {m+n}{m}}$


## Code

Data Input
```{r}
x<-c(16.55, 15.36, 15.94, 16.43, 16.01)
y<-c(16.05, 15.98, 16.10, 15.88, 15.91)
```


```{r}
# first, we need to combine the data for permuting
data<-c(x, y)
m<-length(x)
n<-length(y)

# find all permutations of m observations into the "sample 1" group
x.perm <- combn(data,m)
x.perm <- t(x.perm) # want each permutation as a row in our x.perm matrix

# find the corresponding "sample 2" observations for each permutation
y.perm <- NULL
for (i in 1:choose(m+n, m)){
  y.perm <- rbind(y.perm, setdiff(data, x.perm[i,]))
}

# calculate the RMD statistic for each permutation (each pair of rows in x.perm and y.perm)
RMD <- rep(NA, choose(m+n, m))
for (i in 1:choose(m+n, m)){
  RMD[i] <- mean(abs(x.perm[i,]-median(x.perm[i,])))/mean(abs(y.perm[i,]-median(y.perm[i,])))
}

# solve for the observed RMD statistic with the original data
RMD.obs <- mean(abs(x-median(x)))/mean(abs(y-median(y)))

# solve for the p-value
sum(RMD >= RMD.obs) # use > because this is the upper tail test (would switch for different Ha)
sum(RMD >= RMD.obs)/choose(m+n, m)
```



## Which to use when?
1. Location params
  - If pop 1 and 2 have different location parameters $\implies$ do test of deviances
2. Population distribution shape
  - If two pop have skewed or heavy tailed dists, we prefer rank based tests ( tukey and ansari), b/c they are better at dealing w/ outliers
  - Test on deviances is preferred for symmetric, light tailed distributions
3. Sample Size
  - Rank based gets more powerful for larger $n$

# Kolmogorov-Smirnov Test
## Usage
- **Omnibus Test** is ideal when it is unknown how a difference b/w two populations will manifest itself, the general shapes of the distributions may differ
- Choose a more specific test if you know in what way the distributions are likely to differ

## Procedure

### Hypothesis Tests
- **Null Hypothesis**: $H_0: F_1(x) = F_2(x)$
- **Alternative**: $H_a: F_1(x) \neq F_2(x)$ for some $x$
   - Allows for diff in shape, center (location), or spread (scale)
   
### Test Statistic
1. Calculate $KS$ as maximum absolute difference between the two CDFs at each $x$ in the domain of both
  - $KS = max_x|\hat{F}_1(x)-\hat{F}_2(x)|$
2. Pool $m$ observations from sample 1 and $n$ observations from sample 2 together
3. Permute observations b/w samples s.t. $m$ units are assigned to sample 1 and $n$ are assigned to sample 2. Find empirical cdfs for each sample. Solve $KS$ for this permutation
4. Repeat step 2 all $\binom {m+n}{m}$ times
5. p-value is the fraction of $KS$ as or more extreme than observed
- $\text{p-value} = \frac{\text{number of }KS\text{ 's}~\geq~KS_{obs}}{\binom {m+n}{m}}$ 
- Note: This will *always* be an upper-tail test
- Larger values of $KS$ indicate greater differences b/w $F_1(x)$ and $F_2(x)$

## Code
```{r}
ks.test(x,y,alternative='two.sided')
```

