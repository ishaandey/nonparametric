[["index.html", "Nonparametric Statistics A Beginner’s Guide to Nonparametric Statistics Preface Why This Book? Who Are You? Who Are We?", " Nonparametric Statistics A Beginner’s Guide to Nonparametric Statistics Ishaan Dey1 December 2020 Preface Why This Book? Who Are You? Who Are We? University of Virginia, ishaandey.com↩︎ "],["summary.html", "Summary Background Choosing a Test", " Summary Goal: We’ve got two samples, and want to see if there’s the significance difference in means. Background Comparing differences in means is one of the most commonly used procedures in statistics. Are guys taller than girls? Does this product have better ratings than than other? From introductory statistics, you may remember a two-sample t-test, but that may not always apply. Choosing a Test Ask yourself the following questions: Are my observations randomly sampled from the population? Are the samples independently drawn from each other? Are the population distributions normal, OR, are there more than 40 observations per sample? Are my population variances equal? If you said yes to all of the above, choose the Parametric t-Test. If you said no only to options (3) or (4), consider the Permutation Test. Check the distribution and number of outliers. If the data is skewed, use the median variant, and if there are outliers on both tails, consider using trimmed means. Otherwise, we’ll use the Wilcoxon Rank-Sum, a powerful rank-based test to compare two samples. If we’re interested in generating a confidence interval for the difference, we can use the Mann-Whitney test. It works similarly to the Wilcoxon Rank-Sum, and results in the same p-value. "],["two-sample-t-test.html", "Chapter 1 Parametric t-Test 1.1 Usage 1.2 How It Works 1.3 Code", " Chapter 1 Parametric t-Test 1.1 Usage Use the t-test if the following 4 assumptions are met: Assumptions Random sample from each population Both samples are independent Both population distributions are normal Both population variances are equal Note: By the Central Limit Theorem, we can assume that the sample means will start looking normal at large sample sizes (\\(n \\geq 30\\)). 1.2 How It Works Do we know the population variance \\(\\sigma^2\\)? If so, we’ll use the \\(z\\) distribution: \\(z\\sim N(0,1)\\) Is the population variance \\(\\sigma^2\\) unknown? If not, we’ll then use the \\(t\\) distribution, \\(t\\sim t(df)\\), where \\(df\\) is the minimum of the two sample sizes - 1. 1.3 Code R Python abcd123 abcd123 R Python xyz12314 xyz12341 "],["two-sample-permutation.html", "Chapter 2 Permutation Test 2.1 Usage 2.2 How It Works 2.3 Code 2.4 Variants", " Chapter 2 Permutation Test 2.1 Usage Use the permutation test if the normality assumption is violated, and you’re interested in quantifying the difference in some location parameter: mean, trimmed mean, or median. This works well for smaller sample sizes. Assumptions Random sample from each population Both are sampled independently Both population dists are continuous (not categorical / discrete) Note: No longer assumption of normality, nor equal variances 2.2 How It Works Let \\(D_{observed}\\) represent the difference in means between our samples. Under the null hypothesis, we’d expect that our observations have no difference in means. So, if we were to randomly switch around (permute) the observations across the samples, we’d expect our test statistic \\(D\\) to stay quite close to \\(D_{obs}\\). If sample 1 has \\(m\\) observations, and sample 2 has \\(n\\) observations, there are \\(\\binom {m+n}{m} = \\frac {(m+n)!}{m!n!}\\) permutations when we pool together our observations and reassign them to a group. We can calculate a test statistic \\(D\\) for each one of these permutations. Our p-value is then just the fraction of permutations that have a test statistic \\(D\\) as or more extreme than what was observed \\(D_{obs}\\). P-value Formula \\(p\\text{-value}_{two\\ sided} = \\frac{\\text{# of |D&#39;s|}~\\geq~|D_{obs}|}{\\binom {m+n}{m}}\\) \\(p\\text{-value}_{lower} = \\frac{\\text{# of }D\\leq D_{obs}}{\\binom {m+n}{m}}\\) \\(p\\text{-value}_{upper} = \\frac{\\text{# of }D\\geq D_{obs}}{\\binom {m+n}{m}}\\) Interpretation: Given a p-value of 0.06, there is a 6% chance of observing a difference as extreme as we did under the hypothesis that these samples come from populations with the same distribution. 2.3 Code R Python # Content # Content 2.4 Variants Instead of difference in means, we could use either (1) sums, (2) trimmed means, or (3) medians: Mean/Sum: Use when pop. dist. is short-tailed (normal looking) Trimmed Mean: Use when pop. dist. is symmetric but heavy-tailed (some unusually extreme observations are likely) Median: Use when population distribution is skewed "],["wilcoxon-rank-sum.html", "Chapter 3 Wilcoxon Rank-Sum 3.1 Usage 3.2 How It Works 3.3 Code", " Chapter 3 Wilcoxon Rank-Sum 3.1 Usage Wilcoxon Rank-Sum is great for testing with low sample sizes and outliers, since it uses the rank of the observation as opposed to the value itself. Assumptions Both population distribution are continuous (not categorical / discrete) 3.2 How It Works The goal here is to use ranks, as opposed to the actual values, to identify differences in location between the two parameters. Why? Ranks are much more resistant to outliers, since a singly high observation is now just ranked at the max, doesn’t matter how far above in absolute value it is. We’ll first calculate \\(W_{obs}\\), our test statistic. To do so, we’ll first pool both samples together and rank them, assigning a value of 1 to the smallest observation, and m+n to the largest (since there are now \\(m+n\\) observations in the pooled group). \\(W_{observed}\\) is simply the sum of ranks of sample 1 observations. Why use this instead of the mean of the ranks between the two? Turns out, the sum of ranks of one sample is a linear function of the mean, so there’s a 1:1 correspondence between the two. The sum of ranks is just more consistent and easy to calculate. As a quick example: ## Obs 1 Obs 2 Obs 3 Obs 4 ## sample1 39 49 55 57 ## sample2 31 33 46 NA becomes ## Sample1 Sample1 Sample1 Sample1 Sample2 Sample2 Sample2 ## pooled 39 49 55 57 31 33 46 ## ranks 3 5 6 7 1 2 4 Under the null hypothesis, we’d expect our observations to have no difference in means. So, if we were to randomly switch around (permute) the observations across the samples, we’d expect our test statistic \\(W^*\\) of the particular permutation to remain close to \\(W_{obs}\\). If sample 1 has \\(m\\) observations, and sample 2 has \\(n\\) observations, there are \\(\\binom {m+n}{m} = \\frac {(m+n)!}{m!n!}\\) permutations when we pool together our observations and reassign them to a group. We can calculate a test statistic \\(W^*\\) for each one of these permutations. Our p-value is then just the fraction of permutations that have a test statistic \\(W\\) as or more extreme than what was observed \\(W_{obs}\\): P-value Formula \\(p-val_{two\\ sided} = \\frac{\\text{# of W&#39;s more extreme than } W_{obs} \\text{ across both tails}}{\\binom {m+n}{m}}\\) \\(p-val_{lower} = \\frac{\\text{# of }W\\geq W_{obs}}{\\binom {m+n}{m}}\\) \\(p-val_{upper} = \\frac{\\text{# of }W\\leq W_{obs}}{\\binom {m+n}{m}}\\) Interpretation: Given a p-value of 0.06, there is a 6% chance of observing a difference as extreme as we did under the hypothesis that these samples come from populations with the same distribution. 3.3 Code "],["mann-whitney.html", "Chapter 4 Mann-Whitney 4.1 Usage 4.2 How It Works 4.3 Code 4.4 Note", " Chapter 4 Mann-Whitney 4.1 Usage 4.1.1 Assumptions Both pop. dist are continuous (not categorical / discrete) 4.2 How It Works In a sample of \\(m\\) observations in sample \\(X\\), and \\(n\\) observations in sample \\(Y\\), we want to focus on each possible pair of observations. The test statistic is quite simply \\(U = \\text{# pairs for which } X_i &lt; Y_j\\). The minimum \\(U\\) can be is \\(0\\), while the max is every possible pair, or \\(m*n\\). For example, let’s say we have two samples, and want to see if sample 1 has a lower location than sample 2. Here’s our raw data: ## Obs 1 Obs 2 Obs 3 Obs 4 ## Sample1 31 33 46 40 ## Sample2 39 49 55 57 We then look at every possible combination of the two samples. ## 31 33 40 46 ## 39 NA NA NA NA ## 49 NA NA NA NA ## 55 NA NA NA NA ## 57 NA NA NA NA Now we can compare the values, and check if the values of the first sample (the columns) are greater than the values of the second sample (rows): ## 31 33 40 46 ## 39 0 0 1 1 ## 49 0 0 0 0 ## 55 0 0 0 0 ## 57 0 0 0 0 Our test statistic \\(U\\) is the sum of the matrix, \\(2\\). Under the null hypothesis, we’d expect our test statistic not to be that extreme. That is, if we were to randomly permute our values under different label, we’d need to see that our observed test statistic is far more extreme that the rest of the U statistics before concluding that the null hypothesis doesn’t apply. Formal Hypothesis Test Hypothesis Test: \\[ \\begin{aligned} H_0 &amp;: F_1(x) = F_2(x) \\\\ H_a &amp;: F_1(x) \\geq F_2(x) \\\\ &amp; \\text{with a strict inequality for at least one }x \\end{aligned} \\] P-Value: \\[ \\begin{aligned} p\\text{-value}_{two\\ sided} &amp;= \\frac{\\text{# of U&#39;s farther from } \\frac{mn}{2}}{\\binom {m+n}{m}} \\\\ p\\text{-value}_{lower} &amp;= \\frac{\\text{# of }U\\geq U_{obs}}{\\binom {m+n}{m}} \\\\ p\\text{-value}_{upper} &amp;= \\frac{\\text{# of }U\\leq U_{obs}}{\\binom {m+n}{m}} \\end{aligned} \\] 4.3 Code 4.4 Note The Wilcoxon \\(W\\) is linearly related to Mann Whitney \\(U\\), and results in the same p-value. Proof \\[ \\begin{array}{l} W_{2} \\\\ =\\sum_{j=1}^{n} R\\left(Y_{j}\\right) \\\\ =R\\left(Y_{1}\\right)+R\\left(Y_{2}\\right)+\\cdots+R\\left(Y_{n}\\right) \\\\ =\\left[1+\\left(\\text {number of } X^{\\prime} s \\leq Y_{1}\\right)\\right]+\\left[2+\\left(\\text {number of } X^{\\prime} s \\leq Y_{2}\\right)\\right]+\\cdots \\\\ =[1+\\cdots+n]+\\left[\\left(\\text {number of } X^{\\prime} s \\leq Y_{1}\\right)+\\cdots+\\left(\\text {number of } X^{\\prime} s \\leq Y_{n}\\right)\\right] \\\\ =[1+\\cdots+n]+U \\\\ =\\frac{n(n+1)}{2}+U \\end{array} \\] "],["summary-1.html", "Summary", " Summary Goal: some "],["parametric-paired-t-test.html", "Chapter 5 Parametric Paired T-Test 5.1 Usage 5.2 Procedure 5.3 Code", " Chapter 5 Parametric Paired T-Test 5.1 Usage 5.1.1 Assumptions Paired observations are a random sample (independent) from population of all possible pairs The differences are normally distributed Note: We can assume the sample mean will approach a normal distribution when \\(n_d \\geq 40\\) 5.2 Procedure Paired t-test statistic: \\[ t=\\frac{\\bar{x}_{d}}{S_{d} / \\sqrt{n_{d}}} \\sim t\\left(n_{d}-1\\right) \\] \\(\\bar{x}_{d}\\) is the sample mean difference. \\(s_{d}\\) is the sample standard deviation of the differences. \\(n_{d}\\) is the number of pairs. We’re trying to test the hypothesis: \\[ \\begin{aligned} H_0&amp;: \\mu_d = 0 \\\\ H_a&amp;: \\mu_d &gt; 0,~&lt;0,~\\text{or}~\\neq 0 \\end{aligned} \\] 5.3 Code 5.3 R library(stats) samp.before &lt;- c(1.1, 2.1, 4.2, 3.2, 1.7, 2.2, 2.7) samp.after &lt;- c(3.9, 2.9, 3.8, 1.8, 3.3, 2.8, 2.3) t.test(x=samp.before, y=samp.after, alternative=&#39;two.sided&#39;, paired=T) 5.3 Python from scipi.stats import ttest_rel samp_before = [1.1, 2.1, 4.2, 3.2, 1.7, 2.2, 2.7] samp_after = [3.9, 2.9, 3.8, 1.8, 3.3, 2.8, 2.3] ttest_rel(samp_before, samp_after) "],["paired-permutation-test.html", "Chapter 6 Paired Permutation Test 6.1 Usage 6.2 Procedure 6.3 Code", " Chapter 6 Paired Permutation Test 6.1 Usage By convention, differences are defined as \\(\\text{treatment} - \\text{control}\\). We can use this test if we violate the normality assumption of the paired t-test. However, as we’re still using an average of differences, our test statistic is still subject to outliers. 6.2 Procedure We’ll define \\(D_{obs}\\) as the average of differences between our samples \\[ \\bar{D}_{obs}=\\frac{\\sum_{i=1}^{n} D_{i}}{n} \\] Under the null hypothesis, we’d expect that if we were to randomly switch around (permute) the observed within the pair, we’d see the same test statistic. Since we have \\(n\\) pairs, there are \\(2^n\\) possible arrangements where we swap around the values across the treatment and control group. For each permutation, we’ll find \\(\\bar{D}^*\\), the mean of differences for that particular permutation. More visually: ## Obs 1 Obs 2 Obs 3 Obs 4 Obs 5 ## before 31 38 46 54 43 ## after 39 49 55 57 44 can be permuted within pairs, with one permutation looking like: ## Obs * Obs 2 Obs * Obs 4 Obs 5 ## before* 39 38 55 54 43 ## after* 31 49 46 57 44 but not across pairs, because we’re using a matched pairs design. So, our p-value is then just the fraction of permutations that have a test statistic \\(D\\) as or more extreme than what was observed \\(D_{obs}\\). P-value Formula \\[ \\begin{aligned} P_{\\text {upper tail}} &amp;= \\frac{\\text {number of } \\bar{D}^{\\prime} s \\geq \\bar{D}_{obs}}{2^{n}} \\\\ P_{\\text {lower tail}} &amp;= \\frac{\\text {number of } \\bar{D}^{\\prime} s \\leq \\bar{D}_{obs}}{2^{n}} \\end{aligned} \\] 6.3 Code 6.3 R library(stats) samp.before &lt;- c(1.1, 2.1, 4.2, 3.2, 1.7, 2.2, 2.7) samp.after &lt;- c(3.9, 2.9, 3.8, 1.8, 3.3, 2.8, 2.3) t.test(x=samp.before, y=samp.after, alternative=&#39;two.sided&#39;, paired=T) 6.3 Python # under construction "],["wilcoxon-signed-rank-test.html", "Chapter 7 Wilcoxon Signed-Rank Test 7.1 Usage 7.2 Procedure", " Chapter 7 Wilcoxon Signed-Rank Test 7.1 Usage Signed Ranks are a method of ranking matched pairs data while accounting for the positive or negative nature of the differences. In other words, we can take into account if the treatment or control was higher, without caring about how much higher it was. 7.2 Procedure For each pair of observations, we’ll take the difference as after - before. We’ll then rank these differences by absolute value, smallest to largest, but retain the sign of the rank from the actual difference. Our test statistic, \\(SR_+\\), is the sum of positive signed ranks. More visually: ## Obs 1 Obs 2 Obs 3 Obs 4 Obs 5 ## before 31 38 46 54 45 ## after 39 49 55 57 43 becomes ## Obs 1 Obs 2 Obs 1 Obs 4 Obs 5 ## before 31 38 46 54 45 ## after 39 49 55 57 43 ## diff 8 11 9 3 -2 ## sign.rank 3 5 4 2 -1 Here the the test statistic is found as \\(SR_+ = 3+5+4+2 \\implies SR_+=14\\). In order to find the p-value, we want to ask how likely is it that we found this test statistic just by random chance, assuming the null to be true? In other words, we’ll find every possible permutation of the sign-ranks, and calculate \\(SR_+^*\\) for each one. The p-value is just the fraction of ranks sums as or more extreme than what we observed. P-value Formula \\[ \\begin{aligned} P_{\\text {upper tail}} &amp;=\\frac{\\text {number of } SR_+ \\text{&#39;s} \\geq SR_+}{2^{n}} \\\\ P_{\\text {lower tail}} &amp;=\\frac{\\text {number of } SR_+ \\text{&#39;s} \\leq SR_+}{2^{n}} \\end{aligned} \\] A brief comment on ties: Details Note: When we have multiple pairs with the same difference, we can apply the average rank to the tied observations. Note: If the difference between a pair is 0, we either omit them from the sample, or ignore them (as they don’t count towards \\(SR_+\\)). You’d typically keep them since it gives similar results, and if there many zeros, you’d lose plenty of power from the lower sample size. 7.2 R library(stats) pre &lt;- c(1180, 1210, 1300, 1080, 1120, 1240, 1360, 980) post &lt;- c(1230, 1280, 1310, 1140, 1150, 1200, 1340, 1100) diff &lt;- post-pre wilcox.test(diff, alternative=&quot;greater&quot;) 7.2 Python # under construction "],["sign-test.html", "Chapter 8 Sign Test 8.1 Usage 8.2 Procedure 8.3 Code", " Chapter 8 Sign Test 8.1 Usage 8.2 Procedure 8.2.1 Hypothesis \\(H_{o}: F(x)=1-F(-x)\\) \\(H_{a}: F(x) \\leq 1-F(-x)\\) or \\(H_{a}: F(x) \\geq 1-F(-x)\\) 8.2.2 Test statistic \\(\\mathrm{SN}_{+}\\) is the number of observations greater than 0 If \\(\\mathrm{H}_{\\mathrm{o}}\\) is true, then the distribution of \\(\\mathrm{SN}_{+}\\) is: \\(SN_+ \\sim \\text{Binom}(n, 0.5)\\) or \\(SN_+ \\sim N(0.5 n, \\sqrt{0.25 n})\\) for large enough samples 8.2.3 p value \\[ P_{\\text {upper tail}}=P(SN_+ \\geq SN_{+,obs})\\\\ P_{\\text {lower tail}}=P(SN_+ \\leq SN_{+,obs}) \\] 8.3 Code 8.3 R library(stats) before &lt;- c(1180, 1210, 1300, 1080, 1120, 1240, 1360, 980) after &lt;- c(1230, 1280, 1310, 1140, 1150, 1200, 1340, 1100) diff &lt;- after - before n &lt;- length(diff) SN &lt;- length(diff[diff &gt; 0]) 1 - pbinom(SN, n, 0.5) 8.3 Python # under construction "],["choosing-which-test.html", "Chapter 9 Choosing Which Test", " Chapter 9 Choosing Which Test Look at distribution of differences: If light-tailed and symmetric \\(\\implies\\) Use paired permutation test If skewed or heavy tailed \\(\\implies\\) Use wilcoxon signed-rank test Sign test also is efficient, but generally has low power for smaller \\(n\\) If normal looking \\(\\implies\\) Use sign test "],["summary-sheet.html", "Summary Sheet Background When To Use What", " Summary Sheet How do we test for non-linear association? Background Sometimes the data is strongly correlated, but there is a non-linear pattern. Take the following example: ## 1 2 3 4 5 6 ## 1 16 81 256 625 1296 There is a perfect relationship between the data: \\(y=x^4\\). Yet the correlation, calculated from a linear fit, doesn’t quite reflect that: \\(\\rho=\\) 0.896. What we’re in need of is an improvement of Pearson’s correlation. We’d still like it to describe what happens to \\(Y\\) when \\(X\\) increases, but relax the assumption that the relationship needs to be linear. When To Use What "],["parametric-ols.html", "Chapter 10 Parametric OLS 10.1 Usage 10.2 How It Works 10.3 Code 10.4 Note", " Chapter 10 Parametric OLS 10.1 Usage 10.1.1 Assumption 10.2 How It Works When we fit a line to a slope, we can extract coefficients from our data. Let’s take oft-used mtcars dataset as an example, regressing log(mpg) against log(disp). We can fit a line through this, shown in blue. data(mtcars) model = lm(log(mtcars$mpg)~log(mtcars$disp)) mtcars %&gt;% ggplot(aes(x = log(disp), y = log(mpg))) + geom_point() + geom_smooth(method = &quot;lm&quot;, fill = NA) The equation of this line tells us some important information. Given in the form \\(Y_i = \\beta_0 + \\beta_1X_i+\\varepsilon_i\\), we can estimate coefficients from our linear model as $=$5.381 and \\(\\hat{\\beta_1}\\) -0.459. Crucially: If \\(\\beta_1=0\\), \\(Y\\) doesn’t depend on \\(X_1\\). So naturally, we ask the question: “How well does my estimate of the slope, or \\(\\hat{\\beta_1}\\), actually represent \\(\\beta_1\\)”? In other words, we want to test if \\(\\hat{\\beta_1}\\) is significantly different from \\(0\\). How? We’ll use the t statistic (formula below for those interested) \\[ t_{\\text {slope}} = \\hat{\\beta}_{1} / \\sqrt{ \\frac{\\frac{1}{n-2}{\\sum_{i=1}^{n}\\left(Y_{i}-\\hat{Y_{i}}\\right)^{2}}} {{\\sum_{i=1}^{n}\\left(X_{i}-\\bar{X}\\right)^{2}}} } \\] Assuming our errors, \\(\\varepsilon_i\\), are normally distributed about \\(0\\), our \\(t\\) statistic should follow a t-distribution: \\(t_{\\text {slope}}\\sim t(n-2)\\) 10.3 Code Most regression functions make this super easy to implement. 10.4 Note Pearson’s Correlation is a refinement of our basic OLS model, particularly when there is just 1 explanatory variable \\(X_1\\). When we do so, the \\(R^2\\) of our model is actually just square of the correlation of our variables, \\(cor(X_1,Y)\\). We typically use \\(R^2\\) to examine goodness-of-fit, while Pearson’s correlation shows how \\(X_1\\) and \\(Y\\) move together. "],["permutation-test-for-slope.html", "Chapter 11 Permutation Test for Slope 11.1 Usage 11.2 How it Works", " Chapter 11 Permutation Test for Slope 11.1 Usage The permutation test for the slope helps to determine if there is a significant linear relationship between \\(X\\) and \\(Y\\), when we can’t assume normally distributed error terms. 11.1.1 Assumptions We have a random sample of paired measurements \\((X_i,Y_i)\\). 2.The relationship between \\(X_i\\) and \\(Y_i\\) is linear. The error terms \\(\\varepsilon_i\\) are independent and identically distributed (iid) about zero. However, we no longer assume a Normal distribution. 11.2 How it Works Like many of the previous permutatation tests, we create a p-value that reflects the probability Under \\(H_0\\), there is no relation b/w \\(X\\) and \\(Y\\), so any of the observed \\(Y_i\\)’s could have come from any of the \\(X_i\\)’s. Given \\(n\\) observations, there are \\(n!\\) ways to reorder \\(Y_i\\)’s, because we fix \\(X_i\\)’s and shuffle the \\(Y_i\\)’s 11.2.1 p-value Reshuffle the \\(Y_i\\)’s to get new pairs \\((X_i, Y_i*)\\) Calculate \\(\\hat{\\beta}_1^*\\) for the permuted sample Repeat steps 1 and 2 each of \\(n!\\) times to generate all possible permutations p-value is the fraction of \\(\\hat{\\beta}_1^*\\) as or more extreme than observed: \\[ \\begin{array}{l} p_{\\text {lower tail}}=\\frac{\\# \\hat{\\beta}_{1}^{*} \\leq \\hat{\\beta}_{1, o b s}}{n !} \\\\ p_{\\text {upper tail}}=\\frac{\\# \\hat{\\beta}_{1}^{*} \\geq \\hat{\\beta}_{1, o b s}}{n !} \\\\ p_{\\text {two sided}}=\\frac{\\# |\\hat{\\beta}_{1}^{*}| \\geq |\\hat{\\beta}_{1, o b s}|}{n !} \\end{array} \\] "],["spearmans-rank-correlation.html", "Chapter 12 Spearman’s Rank Correlation 12.1 Usage", " Chapter 12 Spearman’s Rank Correlation 12.1 Usage Spearman’s rank correlation (\\(r_s\\)) calculates the correlation between ranked observations. \\(r\\) calculates the correlation between the pairs \\((X_i,Y_i)\\) \\(r_s\\) calculates the correlation between the pairs \\((~R(X_i),R(Y_i)~)\\) Assumptions We must have independent paired observations. We can’t measure the association of dependent data (i.e. time series). 12.1.1 How it Works By comparing ranks of \\(X_i\\)’s to ranks of \\(Y_i\\)’s, we can see the extent to which \\(Y\\) increases or decreases with \\(X\\). The p-value follows a similar permutation pattern as before. We can reshuffle the obser 12.1.2 p-value Reshuffle the \\(Y_i\\)’s to get new pairs \\((X_i,Y^*_i)\\) Calculate \\(r^*_s\\) for the permuted sample. Repeat steps 1 and 2, \\(n!\\) times to generate all possible permutations. p-value is the fraction of \\({r}_s^*\\)’s as or more extreme than observed: Formal Hypothesis Test Hypothesis Test: \\[ \\begin{aligned} H_0 &amp;: \\rho_s=0 \\\\ H_a &amp;: \\rho_s \\geq 0, \\rho_s \\leq 0, \\text{ or } \\rho_s \\neq 0 \\end{aligned} \\] Note: \\(\\rho_s\\) refers to the population measure, while \\(r_s\\) refers to the observed correlation measure. P-Value: \\[ \\begin{array}{l} p_{\\text {lower tail}}=\\frac{\\# r_{s}^{*} \\leq r_{s, obs}}{n !} \\\\ p_{\\text {upper tail}}=\\frac{\\# r_{s}^{*} \\geq r_{s, obs}}{n !} \\\\ p_{\\text {two sided}}=\\frac{\\# |r_{s}^{*}| \\geq |r_{s, obs}|}{n !} \\end{array} \\] "],["kendalls-tau.html", "Chapter 13 Kendall’s Tau 13.1 Limitations", " Chapter 13 Kendall’s Tau Kendall’s Tau \\(\\tau\\) is a measure of association between X and Y based on concordance. We say that a pair of points \\(\\left(X_{i}, Y_{i}\\right)\\) and \\(\\left(X_{j}, Y_{j}\\right)\\) are: - Concordant if \\(X_{i}&lt;X_{j} \\Rightarrow Y_{i}&lt;Y_{j}\\), or \\(\\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&gt;0\\) - If pairs are more likely to be concordant \\(\\implies\\) positive association - Discordant if \\(X_{i}&lt;X_{j} \\Rightarrow Y_{i}&gt;Y_{j}\\), or \\(\\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&lt;0\\) - If pairs are more likely to be discordant \\(\\implies\\) negative association Kendall’s Tau definition: \\[ \\begin{aligned} \\tau &amp;= 2*P[\\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&gt;0]-1 \\\\ &amp;= 2*Pr(concordance)-1 \\end{aligned} \\] This scales the probability of concordance so it falls on the \\([-1,1]\\) scale 13.0.1 Method In order to find \\(P[\\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&gt;0]\\): We define \\(U_{ij}\\) as an indicator if pairs \\(i,j\\) are concordant: \\[ U_{ij} = \\begin{cases} 1, &amp; \\text{if} \\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&gt;0 \\\\ 0, &amp; \\text{if} \\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)&lt;0 \\end{cases} \\] Note: If there are ties, i.e \\(\\left(X_{i}-X_{j}\\right)\\left(Y_{i}-Y_{j}\\right)=0\\), then \\(U_{ij}=\\frac{1}{2}\\) Then define \\(V_i\\), the number of concordant pairs for a pair \\(i\\), for \\(j&gt;i\\): \\[ V_i = \\sum_{j= i+1}^n U_{ij} \\] The summation \\(\\sum_{i=1}^{n-1} V_i\\) is the total number of concordant pairs in the entire dataset To find the fraction of concordant pairs, compute \\(\\frac{\\sum_{i=1}^{n-1} V_i}{\\binom{n}{2}}\\) Finally, we plug in to get: \\[ r_{\\tau} = 2 * \\frac{\\sum_{i=1}^{n-1} V_i}{\\binom{n}{2}} - 1 \\] We can test if there is significant concordance or discordance with \\(H_0:\\tau=0\\) and \\(H_a: \\tau \\geq 0, \\tau \\leq 0, \\text{ or } \\tau \\neq 0\\) 13.0.2 p-value Reshuffle the \\(Y_i\\)’s to get new pairs \\((X_i,Y^*_i)\\) Calculate \\(r^*_{\\tau}\\) for the permuted sample. Repeat steps 1 and 2, \\(n!\\) times to generate all possible permutations. p-value is the fraction of \\({r}_s^*\\)’s as or more extreme than observed: \\[ \\begin{array}{l} p_{\\text {lower tail}}=\\frac{\\# r_{\\tau}^{*} \\leq r_{\\tau, obs}}{n !} \\\\ p_{\\text {upper tail}}=\\frac{\\# r_{\\tau}^{*} \\geq r_{\\tau, obs}}{n !} \\\\ p_{\\text {two sided}}=\\frac{\\# |r_{\\tau}^{*}| \\geq |r_{\\tau, obs}|}{n !} \\end{array} \\] 13.1 Limitations Both look for a monotonic trend only, neither can detect a parabolic trend (\\(r_s=r_{\\tau}=0\\)) We must have independent paired observations (can’t use time series b/c dependence) "]]
